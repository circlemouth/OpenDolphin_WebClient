# RUN_ID=20251122T071146Z アラート・ダッシュボード設計ログ（モダナイズ版サーバー）

- 日時: 2025-11-22 JST
- 対象: `src/modernized_server/10_オブザーバビリティと運用運転.md` ダッシュボード/アラート追補
- 範囲: Ops/Dev/Biz 向けダッシュボード案、主要アラートルール（閾値/検知・抑止/エスカレーション）、夜間運用とメンテナンスウィンドウ運用
- 禁止事項遵守: Python 実行なし、サーバーコード未変更、ORCA 本番/トライアル操作なし
- 参照チェーン: AGENTS.md → docs/web-client/README.md → docs/server-modernization/phase2/INDEX.md → docs/managerdocs/PHASE2_MANAGER_ASSIGNMENT_OVERVIEW.md → PHASE2_SERVER_FOUNDATION_MANAGER_CHECKLIST

## 1. ダッシュボード案サマリ
- **Ops**: Grafana UID `obs-ops-main`。p95/p99 レイテンシ、5xx/ORCA エラー率、DB/Hikari 利用率、JMS 滞留、SSE 切断率。5 分自動更新、アラートと同一ラベルセット（env/service/facility）。メンテ時間帯を灰帯表示。
- **Dev**: `obs-dev-release`。デプロイ後 24h の回帰指標とトレース例外トップ。前ビルド比差分カードと Feature flag フィルタ。
- **Biz/CS**: `obs-biz-kpi`。受付数/請求件数/ORCA 成功率/アクティブユーザー/p95 応答。15 分更新の週次・月次ビュー。Slack `#biz-alerts` に概要のみ通知（PII なし）。

## 2. 主要アラートルール（Alertmanager → Slack/PagerDuty）
- A1 API レイテンシ: Warning=p95>300ms 10m、Critical=p99>800ms 3/5。抑止: メンテ `time_interval`。通知: Slack → PD ops-primary。
- A2 API エラー率: Warning=5xx>0.5%/5m、Critical=5xx>1% 10m または ORCA 正規化コード!=00 が2%。Canary 用 `version` 分岐。
- A3 DB プール枯渇: Warning=active/max>0.75 5m、Critical>0.90 5m。夜間は Warning のみ。
- A4 JMS/ジョブ滞留: Warning=queue_depth>500 10m or job_wait_p95>60s、Critical=queue_depth>1000 10m。Retry spike と連動抑止。
- A5 Trace サンプリング Drop: Warning=drop rate>10% 10m、Critical>20% 10m。デプロイ直後 15m 抑止。
- A6 ログ取りこぼし: Warning=log_processing_errors>50/min 5m、Critical>200/min 5m。片系障害は Warning、両系で Critical。
- A7 監査ログ欠損: Warning=挿入失敗率>0.5% 10m、Critical>1% 10m または 10 分連続 0 件。本番のみ有効、抑止なし。通知: PD + セキュリティ。
- A8 ORCA 連携: Warning=失敗率>2% 15m、Critical>5% 15m or unreachable 3m。Trial/Local はミュート。本番は CS へ要約同報。
- A9 SSE 切断率: Warning=非クライアント要因>0.2% 1h、Critical>1% 30m。夜間 Warning のみ。
- A10 デプロイ後回帰: Warning=新 version エラー率が旧比+0.5pp 10m、Critical=+1.0pp 10m。Canary 中は PD 抑止、Release Mgr へ DM。
- A5/A6: Stage Tempo 14d compactor24h / Prod Tempo 30d compactor24h（Collector batch 8192, timeout 10s）前提で閾値据置。SRE 口頭確認で drop/log-loss 閾値変更不要を確認済み。

## 3. 夜間運用・メンテナンスウィンドウ
- 夜間一次対応 (22:00–07:00 JST): Critical のみ PagerDuty。Warning は Slack 記録→朝会レビュー。
- 定期メンテ: Stage 水曜 02:00–03:00 JST、Prod 第2日曜 02:00–04:00 JST。A1/A2/A3/A4/A9 を `time_interval` で抑止し、ダッシュボード灰帯表示。
- デプロイ抑止: デプロイ後 15 分間 A1/A2/A5/A10 を自動抑止（`deployed_within=15m` ラベル + `for:10m`）。
- エスカレーション: Ops当番 → SRE 2nd → サービスオーナー（30 分以内）。Biz 影響（A8/A9）は CS へ要約共有。

## 4. A1〜A10 PromQL / recording rule サンプル

### recording rule（共通ラベル: `env`, `service`, `facility`）
```yaml
groups:
- name: recording.rules.a1-a10
  interval: 30s
  rules:
  - record: service:api_latency_p95_seconds
    expr: histogram_quantile(0.95, sum by (le, env, service, facility) (rate(http_server_requests_seconds_bucket{status!~"5.."}[5m])))

  - record: service:api_latency_p99_seconds
    expr: histogram_quantile(0.99, sum by (le, env, service, facility) (rate(http_server_requests_seconds_bucket{status!~"5.."}[5m])))

  - record: service:api_error_ratio
    expr: sum by (env, service, facility) (rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
          /
          sum by (env, service, facility) (rate(http_server_requests_seconds_count[5m]))

  - record: service:orca_error_ratio
    expr: sum by (env, service, facility) (rate(orca_bridge_calls_total{result!="00"}[15m]))
          /
          sum by (env, service, facility) (rate(orca_bridge_calls_total[15m]))

  - record: service:db_pool_utilization
    expr: avg by (env, service, facility) (db_hikari_connections_active / db_hikari_connections_max)

  - record: service:jms_queue_depth
    expr: max by (queue, env, service, facility) (jms_queue_messages_ready)

  - record: service:job_queue_wait_p95_seconds
    expr: histogram_quantile(0.95, sum by (le, env, service, facility) (rate(job_queue_wait_seconds_bucket[10m])))

  - record: service:trace_drop_ratio
    expr: sum by (env, service, facility) (rate(otel_sampler_dropped_total[10m]))
          /
          sum by (env, service, facility) (rate(otel_sampler_decisions_total[10m]))

  - record: service:log_processing_errors_per_minute
    expr: sum by (env, service, facility) (rate(log_processing_errors_total[1m]))

  - record: service:audit_insert_error_ratio
    expr: sum by (env, service, facility) (rate(audit_event_insert_failed_total[10m]))
          /
          sum by (env, service, facility) (rate(audit_event_insert_total[10m]))

  - record: service:sse_disconnect_ratio
    expr: sum by (env, service, facility) (rate(sse_disconnect_total{reason!="client"}[30m]))
          /
          sum by (env, service, facility) (rate(sse_connections_total[30m]))

  - record: service:api_error_ratio_by_version
    expr: sum by (env, service, facility, version) (rate(http_server_requests_seconds_count{status=~"5.."}[10m]))
          /
          sum by (env, service, facility, version) (rate(http_server_requests_seconds_count[10m]))
```

### alerting rule（A1〜A10）
```yaml
groups:
- name: alerts.a1-a10
  rules:
  - alert: A1_ApiLatency_Warning
    expr: service:api_latency_p95_seconds > 0.3
    for: 10m
    labels: {severity: warning}
  - alert: A1_ApiLatency_Critical
    expr: service:api_latency_p99_seconds > 0.8
    for: 3m
    labels: {severity: critical}

  - alert: A2_ApiError_Warning
    expr: service:api_error_ratio > 0.005
    for: 5m
    labels: {severity: warning}
  - alert: A2_ApiError_Critical
    expr: service:api_error_ratio > 0.01 or service:orca_error_ratio > 0.02
    for: 10m
    labels: {severity: critical}

  - alert: A3_DbPool_Warning
    expr: service:db_pool_utilization > 0.75
    for: 5m
    labels: {severity: warning}
  - alert: A3_DbPool_Critical
    expr: service:db_pool_utilization > 0.9
    for: 5m
    labels: {severity: critical}

  - alert: A4_JmsLag_Warning
    expr: service:jms_queue_depth > 500 or service:job_queue_wait_p95_seconds > 60
    for: 10m
    labels: {severity: warning}
  - alert: A4_JmsLag_Critical
    expr: service:jms_queue_depth > 1000
    for: 10m
    labels: {severity: critical}

  - alert: A5_TraceDrop_Warning
    expr: service:trace_drop_ratio > 0.10
    for: 10m
    labels: {severity: warning}
  - alert: A5_TraceDrop_Critical
    expr: service:trace_drop_ratio > 0.20
    for: 10m
    labels: {severity: critical}

  - alert: A6_LogLoss_Warning
    expr: service:log_processing_errors_per_minute > 50
    for: 5m
    labels: {severity: warning}
  - alert: A6_LogLoss_Critical
    expr: service:log_processing_errors_per_minute > 200
    for: 5m
    labels: {severity: critical}

  - alert: A7_AuditMissing_Warning
    expr: service:audit_insert_error_ratio > 0.005
    for: 10m
    labels: {severity: warning, environment: "prod"}
  - alert: A7_AuditMissing_Critical
    expr: service:audit_insert_error_ratio > 0.01
      or (rate(audit_event_insert_total[10m]) == 0)
    for: 10m
    labels: {severity: critical, environment: "prod"}

  - alert: A8_ORCA_Warning
    expr: service:orca_error_ratio > 0.02
    for: 15m
    labels: {severity: warning}
  - alert: A8_ORCA_Critical
    expr: service:orca_error_ratio > 0.05
      or probe_success{target="orca"} == 0
    for: 3m
    labels: {severity: critical}

  - alert: A9_SSEDisconnect_Warning
    expr: service:sse_disconnect_ratio > 0.002
    for: 60m
    labels: {severity: warning}
  - alert: A9_SSEDisconnect_Critical
    expr: service:sse_disconnect_ratio > 0.01
    for: 30m
    labels: {severity: critical}

  - alert: A10_PostDeployRegression_Warning
    expr: |
      (service:api_error_ratio_by_version{version="${NEW_VERSION}"}
       - ignoring(version) group_left() service:api_error_ratio)
       > 0.005
    for: 10m
    labels: {severity: warning, deployed_within: "15m"}
  - alert: A10_PostDeployRegression_Critical
    expr: |
      (service:api_error_ratio_by_version{version="${NEW_VERSION}"}
       - ignoring(version) group_left() service:api_error_ratio)
       > 0.01
    for: 10m
    labels: {severity: critical, deployed_within: "15m"}
```

### Alertmanager 抑止ルール例
```yaml
time_intervals:
  - name: stage_maintenance
    location: Asia/Tokyo
    time_intervals:
    - weekdays: [wednesday]
      times:
      - start_time: 02:00
        end_time: 03:00

  - name: prod_maintenance
    location: Asia/Tokyo
    time_intervals:
    - days_of_month: [8:14]   # 第2日曜付近をカバー
      times:
      - start_time: 02:00
        end_time: 04:00

route:
  group_by: [alertname, env, service, facility]
  routes:
  - matchers: [alertname=~"A1.*|A2.*|A3.*|A4.*|A9.*"]
    active_time_intervals: [stage_maintenance, prod_maintenance]

inhibit_rules:
  - source_matchers: [deployed_within="15m"]
    target_matchers: [alertname=~"A1.*|A2.*|A5.*|A10.*"]
    equal: [env, service, facility]
    # デプロイ直後の A1/A2/A5/A10 を 15 分間抑止。PagerDuty は除外。

receivers:
  - name: slack-modernized-ops
    slack_configs: [{channel: "#modernized-ops"}]
  - name: pagerduty-ops-primary
    pagerduty_configs: [{routing_key: "<pd_key>"}]
```

## 5. エビデンス・残作業
- 本ログにてダッシュボード/アラート案と夜間運用手順を記録。詳細は `src/modernized_server/10_オブザーバビリティと運用運転.md` の「ダッシュボード/アラート設計」節と同期済み。
- 追加 TODO（任意）: Grafana UID/Alertmanager ルール YAML を `artifacts/observability/20251122T071146Z/` 配下へ配置し、実環境の recording rule 名称とラベルを突合する。

## 6. Alertmanager 抑止検証（Stage 実測 2025-11-22 12:24 UTC）
- 手順: `prom/alertmanager:v0.27.0` を stage 用 config で単独起動（`docker run -v /tmp/alertmanager-stage.yml:/etc/alertmanager/alertmanager.yml`）。Route A1/A2/A3/A4/A9 に `mute_time_intervals: [stage_maintenance, validation_now]` を付与し、`inhibit_rules` は DeployWindow → A1/A2/A5/A10 を維持。`validation_now` は土曜終日（検証専用）、stage_maintenance は本番値（水曜 02:00–03:00 JST）。
- 投入アラート: A1/A2/A4/A9（env=stage, facility=f001）+ DeployWindow(deployed_within=15m)。`curl -XPOST http://localhost:9093/api/v2/alerts --data @alerts.json` で送信。
- 結果:
  - A1/A2 は `inhibitedBy=[DeployWindow]` で state=suppressed（`alerts-stage-validation.json` に fingerprint `245fe8256782040f` が紐付く）。
  - A4/A9 は state=active だが dispatcher ログで通知試行なし（5 分間 webhook 送信が DeployWindow のみ）となり、`mute_time_intervals` による抑止を確認。
- 検証ログ: `artifacts/observability/20251122T071146Z/alerts-stage-validation.json`（`/api/v2/alerts/groups` 出力）と `docker logs am-stage`（DeployWindow のみ 12 回 retry）。
- 適用メモ: Stage 反映時は `validation_now` を削除し、`mute_time_intervals:[stage_maintenance]` のみで運用する。Prod への適用は禁止。

## 7. 本番適用ステータス（2025-11-22 時点）
- 状況: 本番クラスタへの接続に必要な `kubeconfig` がリポジトリ内に存在せず、Alertmanager 本番環境での `mute_time_intervals` / `inhibit_rules` 実測は未実施。
- 依存: 本番用 kubeconfig の配置パス（例: `~/.kube/config-prod` など）または取得方法の指示。
- 次アクション: kubeconfig を入手次第、Stage と同手順で本番に適用・短時間実測し、本ログと 10 章・DOC_STATUS を「本番実測済み」に更新する。
